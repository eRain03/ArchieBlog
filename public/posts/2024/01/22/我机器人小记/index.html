<!DOCTYPE html>
<html><head lang="en"><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>《我，机器人》小记 - 未淼 </title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="
第一法则
机器人不得伤害人类，或坐视人类受到伤害；


第二法则
机器人必须服从人类命令，除非命令与第一法则发生冲突；


第三法则
在不违背第一或第二法则之下，机器人可以保护自己。

这不是我第一次读这本书，开篇著名的艾氏机器人三定律首次登场
本书一共9个短篇，以回忆的方式叙述出来，所谓用“机器人心理学“去和异常的机器人打交道，如同书的标题“I,Robot”
书中的机器人三定律的第一法则的电平大于第二法则，第二法则的电平大于第三规则，机器人必须遵守这些“硬代码”否则会自毁
我很喜欢《Liar!》这篇（译文翻译的是“说假话的机器人”） 在生产机器人的的过程中出现了失误，使得机器人（代号：Herbie）拥有了类似读取脑电波的能力，赫比给研究机器人的专家们展现了它读取他们想法的能力，在谈话中赫比向人们透露了其他人的想法，使心理学家苏珊在感情问题上得到了她想知道的答案，赫比告诉了苏珊 米尔顿对她的爱恋之情，苏珊信以为真但在之后的聊天中米尔顿告诉苏珊自己要结婚了，苏珊这才意识到赫比欺骗了她，当众人人质问赫比为什么要撒谎时，赫比被逼的几乎疯癫说出了原因

“机器人不得伤害人类，或坐视人类受到伤害“

原来在赫比的逻辑中第一法则的电平依然是最大的，远超第二法则，赫比认为告诉他们真话会伤害到人类的感情，于是告诉了他们心中希望听到的答案 苏珊博士处于被欺骗和感情上的羞辱报复性地对赫比说
“你不能告诉他们，因为告诉他们，就是伤害他们，可如果你不告诉他们，你就是在伤害他们…”
赫比在心理学家苏珊的思想中感受到了无尽的苦痛，屈辱和仇恨，最终在苏珊创造的逻辑悖论下变成了一坨再也不能思考的废铁

机器人理解不了人类的感情，它只能按照第一法则去避免伤害到人类，没想到这种谎言最终使物理的伤害转变为了精神上的痛苦


这很有意思，不禁令人思考当下火爆的人工智能模型如何判断伤害到人类的范畴，人们也许会允许人在一些事情上犯错，但这种宽容会出现在人工智能上吗?
" />
	<meta property="og:image" content=""/>
	<meta property="og:url" content="http://localhost:1313/posts/2024/01/22/%E6%88%91%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%B0%8F%E8%AE%B0/">
  <meta property="og:site_name" content="未淼 ">
  <meta property="og:title" content="《我，机器人》小记">
  <meta property="og:description" content="第一法则 机器人不得伤害人类，或坐视人类受到伤害；
第二法则 机器人必须服从人类命令，除非命令与第一法则发生冲突；
第三法则 在不违背第一或第二法则之下，机器人可以保护自己。
这不是我第一次读这本书，开篇著名的艾氏机器人三定律首次登场 本书一共9个短篇，以回忆的方式叙述出来，所谓用“机器人心理学“去和异常的机器人打交道，如同书的标题“I,Robot” 书中的机器人三定律的第一法则的电平大于第二法则，第二法则的电平大于第三规则，机器人必须遵守这些“硬代码”否则会自毁
我很喜欢《Liar!》这篇（译文翻译的是“说假话的机器人”） 在生产机器人的的过程中出现了失误，使得机器人（代号：Herbie）拥有了类似读取脑电波的能力，赫比给研究机器人的专家们展现了它读取他们想法的能力，在谈话中赫比向人们透露了其他人的想法，使心理学家苏珊在感情问题上得到了她想知道的答案，赫比告诉了苏珊 米尔顿对她的爱恋之情，苏珊信以为真但在之后的聊天中米尔顿告诉苏珊自己要结婚了，苏珊这才意识到赫比欺骗了她，当众人人质问赫比为什么要撒谎时，赫比被逼的几乎疯癫说出了原因
“机器人不得伤害人类，或坐视人类受到伤害“
原来在赫比的逻辑中第一法则的电平依然是最大的，远超第二法则，赫比认为告诉他们真话会伤害到人类的感情，于是告诉了他们心中希望听到的答案 苏珊博士处于被欺骗和感情上的羞辱报复性地对赫比说 “你不能告诉他们，因为告诉他们，就是伤害他们，可如果你不告诉他们，你就是在伤害他们…” 赫比在心理学家苏珊的思想中感受到了无尽的苦痛，屈辱和仇恨，最终在苏珊创造的逻辑悖论下变成了一坨再也不能思考的废铁
机器人理解不了人类的感情，它只能按照第一法则去避免伤害到人类，没想到这种谎言最终使物理的伤害转变为了精神上的痛苦
这很有意思，不禁令人思考当下火爆的人工智能模型如何判断伤害到人类的范畴，人们也许会允许人在一些事情上犯错，但这种宽容会出现在人工智能上吗?">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-01-22T21:58:34+08:00">
    <meta property="article:modified_time" content="2024-01-22T21:58:34+08:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="《我，机器人》小记">
  <meta name="twitter:description" content="第一法则 机器人不得伤害人类，或坐视人类受到伤害；
第二法则 机器人必须服从人类命令，除非命令与第一法则发生冲突；
第三法则 在不违背第一或第二法则之下，机器人可以保护自己。
这不是我第一次读这本书，开篇著名的艾氏机器人三定律首次登场 本书一共9个短篇，以回忆的方式叙述出来，所谓用“机器人心理学“去和异常的机器人打交道，如同书的标题“I,Robot” 书中的机器人三定律的第一法则的电平大于第二法则，第二法则的电平大于第三规则，机器人必须遵守这些“硬代码”否则会自毁
我很喜欢《Liar!》这篇（译文翻译的是“说假话的机器人”） 在生产机器人的的过程中出现了失误，使得机器人（代号：Herbie）拥有了类似读取脑电波的能力，赫比给研究机器人的专家们展现了它读取他们想法的能力，在谈话中赫比向人们透露了其他人的想法，使心理学家苏珊在感情问题上得到了她想知道的答案，赫比告诉了苏珊 米尔顿对她的爱恋之情，苏珊信以为真但在之后的聊天中米尔顿告诉苏珊自己要结婚了，苏珊这才意识到赫比欺骗了她，当众人人质问赫比为什么要撒谎时，赫比被逼的几乎疯癫说出了原因
“机器人不得伤害人类，或坐视人类受到伤害“
原来在赫比的逻辑中第一法则的电平依然是最大的，远超第二法则，赫比认为告诉他们真话会伤害到人类的感情，于是告诉了他们心中希望听到的答案 苏珊博士处于被欺骗和感情上的羞辱报复性地对赫比说 “你不能告诉他们，因为告诉他们，就是伤害他们，可如果你不告诉他们，你就是在伤害他们…” 赫比在心理学家苏珊的思想中感受到了无尽的苦痛，屈辱和仇恨，最终在苏珊创造的逻辑悖论下变成了一坨再也不能思考的废铁
机器人理解不了人类的感情，它只能按照第一法则去避免伤害到人类，没想到这种谎言最终使物理的伤害转变为了精神上的痛苦
这很有意思，不禁令人思考当下火爆的人工智能模型如何判断伤害到人类的范畴，人们也许会允许人在一些事情上犯错，但这种宽容会出现在人工智能上吗?">

        <link href="http://localhost:1313/css/fonts.fc4f5a86e8e498b54fe94f415531b7bee28ca405d2160b9e55715b497c716193.css" rel="stylesheet">
	

	
	<link rel="stylesheet" type="text/css" media="screen" href="http://localhost:1313/css/main.33535ad1c7d1e61eae52b59547ac79afb3639df98fc2cc22dc2ae9f5a063c72c.css" /><script type="text/javascript"
		src="http://localhost:1313/js/MathJax.js"></script>
		
		<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']],
				displayMath: [['$$','$$'], ['\[','\]']],
				processEscapes: true,
				processEnvironments: true,
				skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
				TeX: { equationNumbers: { autoNumber: "AMS" },
						 extensions: ["AMSmath.js", "AMSsymbols.js"] }
			}
		});
		</script><link rel="stylesheet" href="http://localhost:1313/katex/katex.min.css ">
		<script defer src="http://localhost:1313/katex/katex.min.js"></script>
		<script defer src="http://localhost:1313/katex/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
		
		<script>
			document.addEventListener("DOMContentLoaded", function() {
					renderMathInElement(document.body, {
							delimiters: [
									{left: "$$", right: "$$", display: true},
									{left: "$", right: "$", display: false}
							]
					});
			});
		</script>
		
		
		<link rel="stylesheet" type="text/css" href="http://localhost:1313/css/first.354eb93defa843f69983dc6df53d6af8dc2bf3d3cd5c8970c6c4f1ca724da3ef.css">
		
</head>
<body>
        <div class="content"><header>
	<div class="main">
		<a href="http://localhost:1313/">未淼 </a>
	</div>
	<nav>
		
		<a href="/">Tools</a>
		
		<a href="/posts">Posts</a>
		
		<a href="/tags">Tags</a>
		
		
	</nav>

</header>

<main>
  <article>
    <div class="post-container">
      
      <div class="post-content">
        <div class="title">
          <h1 class="title">《我，机器人》小记</h1>
          <div class="meta">Posted on Jan 22, 2024</div>
        </div>
        
        <section class="body">
          <blockquote>
<p>第一法则
机器人不得伤害人类，或坐视人类受到伤害；</p>
</blockquote>
<blockquote>
<p>第二法则
机器人必须服从人类命令，除非命令与第一法则发生冲突；</p>
</blockquote>
<blockquote>
<p>第三法则
在不违背第一或第二法则之下，机器人可以保护自己。</p>
</blockquote>
<p>这不是我第一次读这本书，开篇著名的艾氏机器人三定律首次登场
本书一共9个短篇，以回忆的方式叙述出来，所谓用“机器人心理学“去和异常的机器人打交道，如同书的标题“I,Robot”
书中的机器人三定律的第一法则的电平大于第二法则，第二法则的电平大于第三规则，机器人必须遵守这些“硬代码”否则会自毁</p>
<p>我很喜欢《Liar!》这篇（译文翻译的是“说假话的机器人”） 在生产机器人的的过程中出现了失误，使得机器人（代号：Herbie）拥有了类似读取脑电波的能力，赫比给研究机器人的专家们展现了它读取他们想法的能力，在谈话中赫比向人们透露了其他人的想法，使心理学家苏珊在感情问题上得到了她想知道的答案，赫比告诉了苏珊 米尔顿对她的爱恋之情，苏珊信以为真但在之后的聊天中米尔顿告诉苏珊自己要结婚了，苏珊这才意识到赫比欺骗了她，当众人人质问赫比为什么要撒谎时，赫比被逼的几乎疯癫说出了原因</p>
<blockquote>
<p>“机器人不得伤害人类，或坐视人类受到伤害“</p>
</blockquote>
<p>原来在赫比的逻辑中第一法则的电平依然是最大的，远超第二法则，赫比认为告诉他们真话会伤害到人类的感情，于是告诉了他们心中希望听到的答案 苏珊博士处于被欺骗和感情上的羞辱报复性地对赫比说
<em>“你不能告诉他们，因为告诉他们，就是伤害他们，可如果你不告诉他们，你就是在伤害他们…”</em>
赫比在心理学家苏珊的思想中感受到了无尽的苦痛，屈辱和仇恨，最终在苏珊创造的逻辑悖论下变成了一坨再也不能思考的废铁</p>
<blockquote>
<p>机器人理解不了人类的感情，它只能按照第一法则去避免伤害到人类，没想到这种谎言最终使物理的伤害转变为了精神上的痛苦</p>
</blockquote>
<blockquote>
<p>这很有意思，不禁令人思考当下火爆的人工智能模型如何判断伤害到人类的范畴，人们也许会允许人在一些事情上犯错，但这种宽容会出现在人工智能上吗?</p>
</blockquote>

        </section>
        <div class="post-tags">
          
          
          
        </div>
      </div>

      
      
    </div>

    <div id="disqus_thread"></div>
<script type="text/javascript">
    (function () {
        
        
        if (window.location.hostname == "localhost")
            return;

        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        var disqus_shortname = '未淼';
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
        Disqus.</a></noscript>
</article>
</main>
<footer>
</footer>

</div>
    </body>
</html>
